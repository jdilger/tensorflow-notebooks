{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AgroForest.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdilger/tensorflow-notebooks/blob/master/AgroForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJIpyTd50j0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f6F2MYxpR3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use logging to maintain more detailed information for reproducibility \n",
        "import logging\n",
        "\n",
        "def tfLog():\n",
        "  logging.basicConfig(level=logging.DEBUG, filename='myapp.log',\n",
        "                      format='%(asctime)s %(levelname)s:%(message)s')\n",
        "  try:\n",
        "    logging.debug('######################################')\n",
        "    logging.debug('Config Settings')\n",
        "    logging.debug('######################################')\n",
        "    logging.debug(\"Bucket:%s\",BUCKET) \n",
        "    logging.debug(\"Folder:%s\",FOLDER)\n",
        "    logging.debug('Training base:%s',TRAINING_BASE)\n",
        "    logging.debug('Eaval base:%s',EVAL_BASE) \n",
        "    logging.debug('Band order:%s',BANDS)\n",
        "    logging.debug('Response:%s',RESPONSE)\n",
        "    logging.debug('Features:%s',FEATURES)\n",
        "    logging.debug('Kernal size:%d',KERNEL_SIZE)\n",
        "    logging.debug('FEATURES_DICT:%s',FEATURES_DICT)\n",
        "    logging.debug('Training size:%d',TRAIN_SIZE)\n",
        "    logging.debug('Eval size:%d',EVAL_SIZE)\n",
        "    logging.debug('batch size:%d',BATCH_SIZE)\n",
        "    logging.debug('Epochs:%d',EPOCHS)\n",
        "    logging.debug('Buffer size:%d',BUFFER_SIZE) \n",
        "    logging.debug('Optimizer:%s',OPTIMIZER) \n",
        "    # logging.debug('Loss:',LOSS)\n",
        "    # logging.debug('Other metrics:',METRICS)\n",
        "  except Exception as e:\n",
        "    print('logging failed')\n",
        "    print(e.args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neIa46CpciXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cloud authentication.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jat01FEoUMqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import, authenticate and initialize the Earth Engine library.\n",
        "import ee\n",
        "try:\n",
        "    ee.Initialize()\n",
        "except Exception as e:\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RnZzcYhcpsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensorflow setup.\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "tf.enable_eager_execution()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obDDH1eDzsch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# INSERT YOUR BUCKET HERE:\n",
        "BUCKET = 'tf-agro-forest'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qs3qZG04u0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import backend\n",
        "# dice coeff and dice loss from Biplov\n",
        "def dice_coeff(y_true, y_pred, smooth=1):\n",
        "    y_true_f = backend.flatten(y_true)\n",
        "    y_pred_f = backend.flatten(y_pred)\n",
        "    intersection = backend.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (backend.sum(y_true_f) + backend.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "# soft dice loss function from Kel\n",
        "# based on https://arxiv.org/pdf/1707.03237.pdf \n",
        "def dice_loss_soft(y_true, y_pred, smooth=1):\n",
        "    intersection = backend.sum(backend.abs(y_true * y_pred), axis=-1)\n",
        "    true_sum = backend.sum(backend.square(y_true),-1) \n",
        "    pred_sum = backend.sum(backend.square(y_pred),-1)\n",
        "    return 1 - ((2. * intersection + smooth) / (true_sum + pred_sum + smooth))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmfKLl9XcnGJ",
        "colab_type": "text"
      },
      "source": [
        "## Set other global variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psz7wJKalaoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import metrics\n",
        "# Specify names locations for outputs in Cloud Storage. \n",
        "FOLDER = 'training_data' \n",
        "TRAINING_BASE = 'training_patches_kernalsize_64'\n",
        "EVAL_BASE = 'training_patches_kernalsize_64'\n",
        "\n",
        "# Specify inputs (Landsat bands) to the model and the response variable.\n",
        "\n",
        "BANDS =['red','green','blue','rmed','rmin','rstd','vv','vh']\n",
        "RESPONSE = ['cocao','forest','seasonalAg'\n",
        ",'urban','water','banana','savana','orchard','mine','shrubland','sparseTree','bare'\n",
        ",'grassland','secondaryForest','nodata']\n",
        "FEATURES = BANDS + RESPONSE\n",
        "\n",
        "# Specify the size and shape of patches expected by the model.\n",
        "KERNEL_SIZE = 64\n",
        "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
        "COLUMNS = [\n",
        "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
        "]\n",
        "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
        "\n",
        "# Sizes of the training and evaluation datasets.\n",
        "TRAIN_SIZE = 16000\n",
        "EVAL_SIZE = 3000\n",
        "\n",
        "# Specify model training parameters.\n",
        "BATCH_SIZE = 1\n",
        "EPOCHS = 10\n",
        "BUFFER_SIZE = 7000\n",
        "OPTIMIZER = 'Adam'\n",
        "LOSS = dice_loss\n",
        "# METRICS =  [\n",
        "#     metrics.get('Accuracy'),\n",
        "#     dice_coeff,]\n",
        "# og metrics if need to switch back \n",
        "METRICS =   [metrics.get('RootMeanSquaredError'),\n",
        "    metrics.get('MeanAbsoluteError'),\n",
        "    metrics.get('Accuracy'),\n",
        "    dice_coeff,]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u57RAvvz2v4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfLog()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8OT9lLv34ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls\n",
        "!cat myapp.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWXrvBE4607G",
        "colab_type": "text"
      },
      "source": [
        "# Training data\n",
        "\n",
        "Load the data exported from Earth Engine into a `tf.data.Dataset`.  The following are helper functions for that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWZ0UXCVMyJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_tfrecord(example_proto):\n",
        "  \"\"\"The parsing function.\n",
        "  Read a serialized example into the structure defined by FEATURES_DICT.\n",
        "  Args:\n",
        "    example_proto: a serialized Example.\n",
        "  Returns: \n",
        "    A dictionary of tensors, keyed by feature name.\n",
        "  \"\"\"\n",
        "  return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
        "\n",
        "\n",
        "def to_tuple(inputs):\n",
        "  \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
        "  Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
        "  Args:\n",
        "    inputs: A dictionary of tensors, keyed by feature name.\n",
        "  Returns: \n",
        "    A dtuple of (inputs, outputs).\n",
        "  \"\"\"\n",
        "  inputsList = [inputs.get(key) for key in FEATURES]\n",
        "  stacked = tf.stack(inputsList, axis=0)\n",
        "  # Convert from CHW to HWC\n",
        "  stacked = tf.transpose(stacked, [1, 2, 0])\n",
        "  return stacked[:,:,:len(BANDS)], stacked[:,:,len(BANDS):]\n",
        "\n",
        "\n",
        "def get_dataset(pattern,flip=False):\n",
        "  \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n",
        "  Get all the files matching the pattern, parse and convert to tuple.\n",
        "  Args:\n",
        "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
        "  Returns: \n",
        "    A tf.data.Dataset\n",
        "  \"\"\"\n",
        "  glob = tf.gfile.Glob(pattern)\n",
        "  dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
        "  dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
        "  dataset = dataset.map(to_tuple, num_parallel_calls=5)\n",
        "  if flip:\n",
        "    dataset = dataset.map(transform)\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25VNQgFtvVKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# custom function to randomly augment the data during training\n",
        "# from kels notebooks\n",
        "# adapted with python random rather than tf. Not sure if it works..\n",
        "import random\n",
        "def transform(features,labels):\n",
        "    x = random.random()\n",
        "    # flip image on horizontal axis\n",
        "    if round(x,2) < 0.12: \n",
        "        feat = tf.image.flip_left_right(features)\n",
        "        labl = tf.image.flip_left_right(labels)\n",
        "    # flip image on vertical axis\n",
        "    elif round(x,2) >=0.12 and round(x,2) < 0.24:\n",
        "        feat = tf.image.flip_up_down(features)\n",
        "        labl = tf.image.flip_up_down(labels)\n",
        "    # transpose image on bottom left corner\n",
        "    elif round(x,2) >=0.24 and round(x,2) < 0.36:\n",
        "        feat = tf.image.flip_left_right(tf.image.flip_up_down(features))\n",
        "        labl = tf.image.flip_left_right(tf.image.flip_up_down(labels))\n",
        "    # rotate to the left 90 degrees\n",
        "    elif round(x,2) >=0.36 and round(x,2) < 0.48:\n",
        "        feat = tf.image.rot90(features,k=1)\n",
        "        labl = tf.image.rot90(labels,k=1)\n",
        "    # rotate to the left 180 degrees\n",
        "    elif round(x,2) >=0.48 and round(x,2) < 0.60:\n",
        "        feat = tf.image.rot90(features,k=2)\n",
        "        labl = tf.image.rot90(labels,k=2)\n",
        "    # rotate to the left 270 degrees\n",
        "    elif round(x,2) >=0.60 and round(x,2) < 0.72:\n",
        "        feat = tf.image.rot90(features,k=3)\n",
        "        labl = tf.image.rot90(labels,k=3)\n",
        "    # transpose image on bottom right corner\n",
        "    elif round(x,2) >=0.72 and round(x,2) < 0.84:\n",
        "        feat = tf.image.flip_left_right(tf.image.rot90(features,k=2))\n",
        "        labl = tf.image.flip_left_right(tf.image.rot90(labels,k=2))\n",
        "    else:\n",
        "        feat = features\n",
        "        labl = labels\n",
        "    print(x,'I WORK')\n",
        "    return feat,labl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg1fa18336D2",
        "colab_type": "text"
      },
      "source": [
        "Use the helpers to read in the training dataset.  Print the first record to check."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm0qRF0fAYcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_training_dataset():\n",
        "\t\"\"\"Get the preprocessed training dataset\n",
        "  Returns: \n",
        "    A tf.data.Dataset of training data.\n",
        "  \"\"\"\n",
        "\tglob = 'gs://' + BUCKET + '/' + FOLDER + '/' + TRAINING_BASE + '*'\n",
        "\tdataset = get_dataset(glob,flip=False)\n",
        "\tdataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\treturn dataset\n",
        "\n",
        "training = get_training_dataset()\n",
        "\n",
        "# print(iter(training.take(1)).next())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-cQO5RL6vob",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation data\n",
        "\n",
        "Now do the same thing to get an evaluation dataset.  Note that unlike the training dataset, the evaluation dataset has a batch size of 1, is not repeated and is not shuffled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieKTCGiJ6xzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_eval_dataset():\n",
        "\t\"\"\"Get the preprocessed evaluation dataset\n",
        "  Returns: \n",
        "    A tf.data.Dataset of evaluation data.\n",
        "  \"\"\"\n",
        "\tglob = 'gs://' + BUCKET + '/' + FOLDER + '/' + EVAL_BASE + '*'\n",
        "\tdataset = get_dataset(glob)\n",
        "\tdataset = dataset.batch(1).repeat()\n",
        "\treturn dataset\n",
        "\n",
        "evaluation = get_eval_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JIE7Yl87lgU",
        "colab_type": "text"
      },
      "source": [
        "# Model\n",
        "\n",
        "Here we use the Keras implementation of the U-Net model as found [in the TensorFlow examples](https://github.com/tensorflow/models/blob/master/samples/outreach/blogs/segmentation_blogpost/image_segmentation.ipynb).  The U-Net model takes 256x256 pixel patches as input and outputs per-pixel class probability, label or a continuous output.  We can implement the model essentially unmodified, but will use mean squared error loss on the sigmoidal output since we are treating this as a regression problem, rather than a classification problem.  Since impervious surface fraction is constrained to [0,1], with many values close to zero or one, a saturating activation function is suitable here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zSFpZ5Tbh688",
        "colab": {}
      },
      "source": [
        "# re orginize model...\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import metrics\n",
        "from tensorflow.python.keras import optimizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "# model = models.Sequential()\n",
        "visible =  layers.Input(shape=[None, None, len(BANDS)])\n",
        "# from stackexchange\n",
        "enocded_imag = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(visible)\n",
        "enocded_imag = layers.MaxPooling2D((2, 2), padding='same')(enocded_imag)\n",
        "enocded_imag = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(visible)\n",
        "enocded_imag = layers.MaxPooling2D((2, 2), padding='same')(enocded_imag)\n",
        "enocded_imag = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(enocded_imag)\n",
        "enocded_imag = layers.MaxPooling2D((2, 2), padding='same')(enocded_imag)\n",
        "enocded_imag = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(enocded_imag)\n",
        "enocded_imag = layers.MaxPooling2D((2, 2), padding='same')(enocded_imag)\n",
        "\n",
        "decoded_imag = layers.Conv2D(64, (2, 2), activation='relu', padding='same')(enocded_imag)\n",
        "decoded_imag = layers.UpSampling2D((2, 2),interpolation='bilinear')(decoded_imag)\n",
        "decoded_imag = layers.BatchNormalization()(decoded_imag)\n",
        "decoded_imag = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(decoded_imag)\n",
        "decoded_imag = layers.UpSampling2D((2, 2),interpolation='bilinear')(decoded_imag)\n",
        "decoded_imag = layers.BatchNormalization()(decoded_imag)\n",
        "decoded_imag = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(decoded_imag)\n",
        "decoded_imag = layers.UpSampling2D((2, 2),interpolation='bilinear')(decoded_imag)\n",
        "decoded_imag = layers.BatchNormalization()(decoded_imag)\n",
        "decoded_imag = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(decoded_imag)\n",
        "# decoded_imag = layers.Dropout(0.2)(decoded_imag)\n",
        "\n",
        "outBranch = layers.Conv2D(128, 3, activation='relu', \n",
        "                          padding='same',name=\"out_block_conv1\")(decoded_imag)\n",
        "outBranch = layers.SpatialDropout2D(rate=0.2,seed=1,name=\"out_block_spatialdrop\")(outBranch)\n",
        "outBranch = layers.BatchNormalization(name=\"out_block_batchnorm1\")(outBranch)\n",
        "outBranch = layers.Conv2D(len(RESPONSE), (1, 1), activation='relu')(outBranch)\n",
        "outputs = layers.Activation(\"softmax\")(outBranch)\n",
        "model = models.Model(inputs=visible, outputs=outputs)\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "# plot graph\n",
        "plot_model(model, to_file='convolutional_neural_network.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeAyx_fvjn0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# re orginize model...for 8x8 patch\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import metrics\n",
        "from tensorflow.python.keras import optimizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "# model = models.Sequential()\n",
        "visible =  layers.Input(shape=[None, None, len(BANDS)])\n",
        "# from stackexchange\n",
        "enocded_imag = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(visible)\n",
        "enocded_imag = layers.MaxPooling2D((2, 2), padding='same')(enocded_imag)\n",
        "\n",
        "decoded_imag = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(enocded_imag)\n",
        "decoded_imag = layers.UpSampling2D((2, 2),interpolation='bilinear')(decoded_imag)\n",
        "decoded_imag = layers.BatchNormalization()(decoded_imag)\n",
        "decoded_imag = layers.Dropout(0.2)(decoded_imag)\n",
        "\n",
        "# outBranch = layers.BatchNormalization(name=\"out_block_batchnorm1\")(decoded_imag)\n",
        "outBranch = layers.Conv2D(len(RESPONSE), (1, 1), activation='relu')(decoded_imag)\n",
        "outputs = layers.Activation(\"softmax\")(outBranch)\n",
        "model = models.Model(inputs=visible, outputs=outputs)\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "# plot graph\n",
        "plot_model(model, to_file='convolutional_neural_network.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsnnnz56yS3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trying new cnn>dnn not working well...\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import metrics\n",
        "from tensorflow.python.keras import optimizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "model = models.Sequential()\n",
        "visible =  layers.Input(shape=[None, None, len(BANDS)])\n",
        "conv1 = layers.Conv2D(32, kernel_size=4, padding='same',activation='relu')(visible)\n",
        "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "conv2 = layers.Conv2D(16, kernel_size=4, padding='same',activation='relu')(pool1)\n",
        "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "flat = layers.GlobalMaxPooling2D()(pool2)\n",
        "# flat = layers.Flatten()(pool2)\n",
        "hidden1 = layers.Dense(128,activation='relu')(flat)\n",
        "output = layers.Conv1D(len(RESPONSE), activation='softmax')(hidden1)\n",
        "# outBranch = layers.Conv2D(len(RESPONSE), (1, 1), activation='sigmoid')(flat)\n",
        "# outputs = layers.Activation(\"softmax\")(outBranch)\n",
        "model = models.Model(inputs=visible, outputs=output)\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "# plot graph\n",
        "plot_model(model, to_file='convolutional_neural_network.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb--4EG4Xuow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import metrics\n",
        "from tensorflow.python.keras import optimizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "# model = models.Sequential()\n",
        "visible =  layers.Input(shape=[None, None, len(BANDS)])\n",
        "# from stackexchange\n",
        "enocded_imag = layers.Conv2D(64, (7, 7), activation='relu', padding='same')(visible)\n",
        "enocded_imag = layers.MaxPooling2D((2, 2), padding='same')(enocded_imag)\n",
        "enocded_imag = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(visible)\n",
        "enocded_imag = layers.MaxPooling2D((2, 2), padding='same')(enocded_imag)\n",
        "enocded_imag = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(enocded_imag)\n",
        "enocded_imag = layers.MaxPooling2D((2, 2), padding='same')(enocded_imag)\n",
        "enocded_imag = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(enocded_imag)\n",
        "enocded_imag = layers.MaxPooling2D((2, 2), padding='same')(enocded_imag)\n",
        "\n",
        "decoded_imag = layers.Conv2D(8, (2, 2), activation='relu', padding='same')(enocded_imag)\n",
        "decoded_imag = layers.UpSampling2D((2, 2),interpolation='bilinear')(decoded_imag)\n",
        "decoded_imag = layers.BatchNormalization()(decoded_imag)\n",
        "decoded_imag = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(decoded_imag)\n",
        "decoded_imag = layers.UpSampling2D((2, 2),interpolation='bilinear')(decoded_imag)\n",
        "decoded_imag = layers.BatchNormalization()(decoded_imag)\n",
        "decoded_imag = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(decoded_imag)\n",
        "decoded_imag = layers.UpSampling2D((2, 2),interpolation='bilinear')(decoded_imag)\n",
        "decoded_imag = layers.BatchNormalization()(decoded_imag)\n",
        "decoded_imag = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(decoded_imag)\n",
        "# decoded_imag = layers.Dropout(0.2)(decoded_imag)\n",
        "\n",
        "outBranch = layers.Conv2D(128, 3, activation='relu', \n",
        "                          padding='same',name=\"out_block_conv1\")(decoded_imag)\n",
        "outBranch = layers.SpatialDropout2D(rate=0.2,seed=1,name=\"out_block_spatialdrop\")(outBranch)\n",
        "outBranch = layers.BatchNormalization(name=\"out_block_batchnorm1\")(outBranch)\n",
        "outBranch = layers.Conv2D(len(RESPONSE), (1, 1), activation='relu')(outBranch)\n",
        "outputs = layers.Activation(\"softmax\")(outBranch)\n",
        "model = models.Model(inputs=visible, outputs=outputs)\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "# plot graph\n",
        "plot_model(model, to_file='convolutional_neural_network.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49TETp8tFWjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\t# trying new cnn>dnn not working well\n",
        "model.compile(\n",
        "    \n",
        "\t\toptimizer=optimizers.Adam(lr=0.001), \n",
        "\t\tloss=dice_loss_soft,#losses.get('categorical_crossentropy'),#dice_loss_soft,#losses.get('categorical_crossentropy'), #losses.get(LOSS),dice_loss_soft\n",
        "    # binaryxentro works in both loss and metics\n",
        "    # metrics.CategoricalAccuracy()\n",
        "\t\tmetrics=[metrics.get('CategoricalAccuracy')])# dice_coef,[metrics.get(metric) for metric in METRICS]) #[metrics.get('CategoricalAccuracy')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzzaWxOhSxBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = model\n",
        "MODEL_FOLDER = 'smalldicelosssoft'\n",
        "history = m.fit(\n",
        "    x=training, \n",
        "    epochs=EPOCHS, \n",
        "    steps_per_epoch=int(TRAIN_SIZE / BATCH_SIZE), \n",
        "    validation_data=evaluation,\n",
        "    validation_steps=EVAL_SIZE)\n",
        "\n",
        "modelDir = 'gs://{}/{}/{}'.format(BUCKET,FOLDER,MODEL_FOLDER)\n",
        "\n",
        "# tf.contrib.saved_model.save_keras_model(m, modelDir)\n",
        "# TODO: add something to move log to model folder\n",
        "# tfLog()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5M6bo3GbgfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelDir = 'gs://{}/{}/{}'.format(BUCKET,FOLDER,MODEL_FOLDER+'_2')\n",
        "tf.contrib.saved_model.save_keras_model(m, modelDir)\n",
        "# TODO: add something to move log to model folder\n",
        "# tfLog()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DCHMtiqYlbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the results of model training\n",
        "# get numpy and matplotlib.pyplot\n",
        "# from kels notebooks\n",
        "%pylab inline\n",
        "fig, ax = plt.subplots(nrows=2, sharex=True, figsize=(10,5.5))\n",
        "\n",
        "ax[0].plot(history.history['loss'],color='#1f77b4',label='Training Loss')\n",
        "ax[0].plot(history.history['val_loss'],linestyle=':',marker='o',markersize=3,color='#1f77b4',label='Validation Loss')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].set_ylim(0.0,0.4)\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(history.history['categorical_accuracy'],color='#ff7f0e',label='Training Acc.')\n",
        "ax[1].plot(history.history['val_categorical_accuracy'],linestyle=':',marker='o',markersize=3,color='#ff7f0e',label='Validation Acc.')\n",
        "ax[1].set_ylabel('Accuracy')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[1].legend(loc=\"lower right\")\n",
        "\n",
        "ax[1].set_xticks(history.epoch)\n",
        "ax[1].set_xticklabels(range(1,len(history.epoch)+1))\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[1].set_ylim(0.0,1)\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "# plt.savefig(\"/content/drive/My Drive/landsat_qa_samples/training.png\",dpi=300,)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Sp69RMxyC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# og gee tf fcnn\n",
        "\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import metrics\n",
        "from tensorflow.python.keras import optimizers\n",
        "\n",
        "def conv_block(input_tensor, num_filters):\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('relu')(encoder)\n",
        "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
        "\tencoder = layers.BatchNormalization()(encoder)\n",
        "\tencoder = layers.Activation('relu')(encoder)\n",
        "\treturn encoder\n",
        "\n",
        "def encoder_block(input_tensor, num_filters):\n",
        "\tencoder = conv_block(input_tensor, num_filters)\n",
        "\tencoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
        "\treturn encoder_pool, encoder\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "\tdecoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "\tdecoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('relu')(decoder)\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('relu')(decoder)\n",
        "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = layers.BatchNormalization()(decoder)\n",
        "\tdecoder = layers.Activation('relu')(decoder)\n",
        "\treturn decoder\n",
        "\n",
        "def get_model():\n",
        "\tinputs = layers.Input(shape=[None, None, len(BANDS)]) # 256\n",
        "\tencoder0_pool, encoder0 = encoder_block(inputs, 32) # 128\n",
        "\tencoder1_pool, encoder1 = encoder_block(encoder0_pool, 64) # 64\n",
        "\tencoder2_pool, encoder2 = encoder_block(encoder1_pool, 128) # 32\n",
        "\tencoder3_pool, encoder3 = encoder_block(encoder2_pool, 256) # 16\n",
        "\tencoder4_pool, encoder4 = encoder_block(encoder3_pool, 512) # 8\n",
        "\tcenter = conv_block(encoder4_pool, 1024) # center\n",
        "\tdecoder4 = decoder_block(center, encoder4, 512) # 16\n",
        "\tdecoder3 = decoder_block(decoder4, encoder3, 256) # 32\n",
        "\tdecoder2 = decoder_block(decoder3, encoder2, 128) # 64\n",
        "\tdecoder1 = decoder_block(decoder2, encoder1, 64) # 128\n",
        "\tdecoder0 = decoder_block(decoder1, encoder0, 32) # 256\n",
        "\toutBranch = layers.Conv2D(len(RESPONSE), (1, 1), activation='relu')(decoder0)\n",
        "\toutputs = layers.Activation(\"softmax\")(outBranch)\n",
        "\n",
        "\tmodel = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "#og compile \n",
        "\tmodel.compile(\n",
        "\t\toptimizer=optimizers.get(OPTIMIZER), \n",
        "\t\tloss=losses.get(LOSS),\n",
        "\t\tmetrics=[metrics.get('CategoricalAccuracy')])#metrics=[metrics.get(metric) for metric in METRICS])\n",
        "\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2BfhwQByBly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = get_model()\n",
        "MODEL_FOLDER = 'testsoftmaxmeh'\n",
        "m.fit(\n",
        "    x=training, \n",
        "    epochs=EPOCHS, \n",
        "    steps_per_epoch=int(TRAIN_SIZE / BATCH_SIZE), \n",
        "    validation_data=evaluation,\n",
        "    validation_steps=EVAL_SIZE)\n",
        "\n",
        "modelDir = 'gs://{}/{}/{}'.format(BUCKET,FOLDER,MODEL_FOLDER)\n",
        "\n",
        "tf.contrib.saved_model.save_keras_model(m, modelDir)\n",
        "# TODO: add something to move log to model folder\n",
        "tfLog()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu_E7OTDBCoS",
        "colab_type": "text"
      },
      "source": [
        "# Training the model\n",
        "\n",
        "You train a Keras model by calling `.fit()` on it.  Here we're going to train for 10 epochs, which is suitable for demonstration purposes.  For production use, you probably want to optimize this parameter, for example through [hyperparamter tuning](https://cloud.google.com/ml-engine/docs/tensorflow/using-hyperparameter-tuning)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2XrwZHp66j4",
        "colab_type": "text"
      },
      "source": [
        "Note that the notebook VM is sometimes not heavy-duty enough to get through a whole training job, especially if you have a large buffer size or a large number of epochs.  You can still use this notebook for training, but may need to set up an alternative VM ([learn more](https://research.google.com/colaboratory/local-runtimes.html)) for production use.  Alternatively, you can package your code for running large training jobs on Google's AI Platform [as described here](https://cloud.google.com/ml-engine/docs/tensorflow/trainer-considerations).  The following code loads a pre-trained model, which you can use for predictions right away."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YcsnqOA2du_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.tools import saved_model_utils\n",
        "# \n",
        "# modelDir = 'gs://{}/{}/model-dice-256'.format('ee-tf',FOLDER)\n",
        "\n",
        "meta_graph_def = saved_model_utils.get_meta_graph_def(modelDir, 'serve')\n",
        "inputs = meta_graph_def.signature_def['serving_default'].inputs\n",
        "outputs = meta_graph_def.signature_def['serving_default'].outputs\n",
        "\n",
        "# Just get the first thing(s) from the serving signature def.  i.e. this\n",
        "# model only has a single input and a single output.\n",
        "input_name = None\n",
        "for k,v in inputs.items():\n",
        "  input_name = v.name\n",
        "  break\n",
        "\n",
        "output_name = None\n",
        "for k,v in outputs.items():\n",
        "  output_name = v.name\n",
        "  break\n",
        "\n",
        "# Make a dictionary that maps Earth Engine outputs and inputs to \n",
        "# AI Platform inputs and outputs, respectively.\n",
        "import json\n",
        "input_dict = \"'\" + json.dumps({input_name: \"array\"}) + \"'\"\n",
        "output_dict = \"'\" + json.dumps({output_name: \"class\"}) + \"'\"\n",
        "\n",
        "# Put the EEified model next to the trained model directory.\n",
        "# TODO: add eeidied dir, project into to log, add output name\n",
        "EEIFIED_DIR = '{}/eeified'.format(modelDir)\n",
        "PROJECT = 'john-ee-282116'\n",
        "print(input_dict,output_dict)\n",
        "# You need to set the project before using the model prepare command.\n",
        "!earthengine set_project {PROJECT}\n",
        "!earthengine model prepare --source_dir {modelDir} --dest_dir {EEIFIED_DIR} --input {input_dict} --output {output_dict}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TaQgGhcePnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelDir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E0OpHQo5DKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time \n",
        "MODEL_NAME = 'tf256_small2large_2ai'\n",
        "\n",
        "VERSION_NAME = 'v' + str(int(time.time()))\n",
        "print('Creating version: ' + VERSION_NAME)\n",
        "\n",
        "!gcloud ai-platform models create {MODEL_NAME} --project {PROJECT}\n",
        "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
        "  --project {PROJECT} \\\n",
        "  --model {MODEL_NAME} \\\n",
        "  --origin {EEIFIED_DIR} \\\n",
        "  --runtime-version=1.14 \\\n",
        "  --framework \"TENSORFLOW\" \\\n",
        "  --python-version=3.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RJpNfEUS1qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a trained model. \n",
        "MODEL_DIR = 'gs://ee-tf/tahoe-ogfw-02292020/model-ogwf-256'\n",
        "m = tf.contrib.saved_model.load_keras_model(MODEL_DIR)\n",
        "help(m.summary())\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}